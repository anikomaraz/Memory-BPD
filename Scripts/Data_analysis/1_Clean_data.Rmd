---
title: "Data_cleaning_MemoryBPD"
output: html_document
---

```{r setup_finetune, include=T, echo=FALSE}

# call helper files
source("../functions_bpd_memo.R")
source("../not_approved_screening_sessions.R")
source("../ipstack_key.R")

# load packages
packages <- c("ggplot2", "tidyverse", "lubridate", "data.table", "here", "rjson")
load_my_packages(packages)

# user-defined options
overwrite_data = TRUE  # if TRUE, then the final data will be saved (overwritten)
```


-------------------------------------------
#Formatting data
-------------------------------------------


```{r get_clean_data, eval=TRUE, echo=FALSE}
get_bpdMemo_raw_data(my_version="180726") # returns data_raw AND  data_t1time
get_bpdMemo_raw_data_mturk(my_version="180831") # returns data_raw_mturk AND  data_t1time_mturk
mturk_full_data <- read.csv2(file="../../Data/Raw_data/mturk_full_data_withIP_180820.csv") # returns mturk data

# format columns, and merge facebook and mturk data (from formr)
data_raw[, grep("^lec", colnames(data_raw), value=T)] <- sapply(data_raw[, grep("^lec", colnames(data_raw), value=T)], as.character)
data_raw_mturk[, grep("^lec", colnames(data_raw_mturk), value=T)] <- sapply(data_raw_mturk[, grep("^lec", colnames(data_raw_mturk), value=T)], as.character)
data_raw <- bind_rows(data_raw, data_raw_mturk)

# merge facebook/mturk data from formr with data from mturk
data_raw <- full_join(data_raw, 
                      mturk_full_data[, c("session", "survey_virgin", "source", "screen_attention_check_error")], 
                      by="session")

# merge facebook and mturk time data (from formr)
data_t1time_mturk$answered_relative.t1 <- as.numeric(data_t1time_mturk$answered_relative.t1)
time_vars <-  c("session", "item_name.t1", "answered_relative.t1")
data_time <- bind_rows(data_t1time[, time_vars], data_t1time_mturk[, time_vars])

## create two versions: full and without variables based on which participants could potentially be identified
write.csv2(data_raw, "../../Data/Raw_data/data_raw_full_identifiable_180831.csv")
write.csv2( data_raw[, -grep(c("^ip[.]+|ip_address|^browser.|nickname|^email"), names(data_raw))], "../../Data/data_raw_full_180831.csv")
write.csv2(data_time, "../../Data/data_raw_full_time_180831.csv")


```

```{r data_read, eval=T, echo=F}
data_raw <- read.csv2("../../Data/Raw_data/data_raw_full_identifiable_180827.csv")
data_time <- read.csv2("../../Data/data_raw_full_time_180827.csv")

```


```{r geolocation, eval=T, echo=T}
# register at ipstack to obtain your own access key
my_access_key = my_access_key3

# access the geolocation via ip address (using ipstatic.com, a free service)
get_geo_ip <- function(ip) {
  url <- paste(c("http://api.ipstack.com/", ip, "?access_key=", my_access_key), collapse='')
  geolocation <- fromJSON(readLines(url, warn=FALSE))
    #geolocation <- readLines(url, warn = F)
  return(geolocation$country_code)
    }   

# data_ip <- data_raw[!is.na(data_raw$ip_address.sc),]
data_raw <- data_raw[lapply(data_raw$ip_address.sc, str_length) > 0L,]

```

```{r ip_address_count}
table(as.data.frame(table(data_raw$ip_address.sc))[,2])
ip_adress_count <- rle(sort(as.character(data_raw$ip_address.sc)))
ip_address_data <- data.frame(ip_address=ip_adress_count$values, 
                              n=ip_adress_count$lengths)
ip_address_data[ip_address_data$n > 7, ]  # IPs with 20 and 47 entries were my test sessions, IP address starting with "141.". was my phone test session
ip_9 = c("104.131.19.173", "104.236.70.228")
data_raw[data_raw$ip_address.sc %in% ip_9, ]

# score if suspicous
ip_largerThanOne <- as.character(ip_address_data[ip_address_data$n >= 2, ]$ip_address)
data_raw$ip_suspicious <- ifelse(data_raw$ip_address.sc %in% ip_largerThanOne, 1, 0)
table(data_raw$ip_suspicious)
```


```{r remove_data1, eval=T, echo=F}
## get rid of test and empty sessions 
data_clean <- data_raw[!data_raw$session %in% remove_test_sessions,]
data_time$session <- sapply(data_time$session, as.character) 
data_time <- data_time[!(data_time$session %in% remove_test_sessions), ]
N1_notest <- length(data_clean$session)

## remove duplicate rows (and keep only the first "attempt" to fill out the survey):
length(data_clean$session) - length(unique(data_clean$session)) # returns the number of duplicates
data_clean <- data_clean[!duplicated(data_clean$session), ]
N2_nodupl <- length(data_clean$session)

## remove those who did not fill out the screening
data_clean <- data_clean[!is.na(data_clean$bpd_s1.sc),]
N3_noblankscreening <- length(data_clean$session)

## get rid of those those who did not pass the screening attention check (screening for MTurk only)
data_clean <- data_clean[!data_clean$session %in% remove_screen_failed,] 
data_time <- data_time[!(data_time$session %in% remove_screen_failed), ]
N4_nofailtest <- length(data_clean$session)

## participants who screened positive
bpd_items <- c("bpd_s1.sc", "bpd_s2.sc", "bpd_s3.sc", "bpd_s4.sc", "bpd_s5.sc", 
               "bpd_s6.sc", "bpd_s7.sc", "bpd_s8.sc", "bpd_s9.sc", "bpd_s10.sc")
data_clean$screen_bpd <- rowSums(data_clean[, bpd_items]) 
data_clean$screen_bpd_posNeg <- data_clean$screen_bpd > 15
data_clean$screen_positive <- ifelse(data_clean$screen_bpd_posNeg & 
                                       data_clean$age.sc != "under_18" &  
                                       data_clean$age.sc < 65 &  
                                       data_clean$residence.sc == "United_States", T, F &  
                                       data_clean$screen_attention_check.sc == "2")   
data_clean <- data_clean[data_clean$screen_positive == T, ]
N5_screenpostive <- length(data_clean$session)

## participants with no missing data on PANAS at t1
data_clean <- data_clean[!is.na(data_clean$panas_1.t1),]
N6_nomissing <- length(data_clean$session)

## filter those who have full data (t1-t4)
data_clean$session_full <- !is.na(data_clean[,"panas_1.t4"])
N7_sessionfull <- sum(data_clean$session_full)

## sample N accross data cleaning
sample_N <- list(
  "test sessions excluded, no. of people clicking on the website:" = N1_notest, 
   "all data:" = N2_nodupl, 
   "participants who were screened:" = N3_noblankscreening, 
  "participants who passed the screening attention check (screening for MTurk only):" = N4_nofailtest, 
   "participants screened positive" = N5_screenpostive, # baseline data
  "participiants with no missing data on T1 (PANAS) meaning they did Part1  (BASELINE)" = N6_nomissing,
  "participants who have full data (t1-t4) (LONGITUDINAL)" = N7_sessionfull) # longitudinal data

sample_N


```


```{r att_check_calculate_baseline, eval=TRUE, echo=FALSE}
# ATTENTION CHECK 

# errors on the classic attention check items
data_clean$att_check_item_errors_t1 <- calculate_att_check_item_errors_t1(data=data_clean, "att_check1.t1", "att_check2.t1")

# errors on video-content-related attention check items
data_clean$att_check_video_errors <- calculate_att_check_video_errors(
  data=data_clean, vars=c( "att_check_videoGr1.t1", "att_check_videoGr2.t1", "att_check_videoGr3.t1", "att_check_videoGr4.t1", 
                           "att_check_videoGr5.t1", "att_check_videoGr6.t1", "att_check_videoGr7.t1", "att_check_videoGr8.t1", 
                           "att_check_videoGr9.t1")) 

# calculate time spent watching the videos
data_time <- data_time[!is.na(data_time$session),]
sum(is.na(data_time$session))
vid1_watch_time <- calculate_vid1_difftime(data=data_time)
vid2_watch_time <- calculate_vid2_difftime(data=data_time)

# merge this data with the clean dataset
data_final_vid12 <- full_join(vid1_watch_time, vid2_watch_time, by="session") %>% 
  full_join(data_clean, by="session")

# calculate if watch time is less than the length of the video (=error)
vid1_too_short <- calculate_vid1_too_short(data=data_final_vid12)
vid2_too_short <- calculate_vid2_too_short(data=data_final_vid12)

# merge this data to the final
data_final <- full_join(vid1_too_short[, c("vid1_too_short", "vid1_difftime", "session")], 
                        vid2_too_short[, c("vid2_too_short", "vid2_difftime", "session")], by="session") %>% 
  full_join(data_clean, by="session")
#write.csv2(data_final, file="./data_final_tmp.csv")

# calculate overall error score
data_final$att_check_sum_t1 <- rowSums(data_final[, c("att_check_item_errors_t1", "att_check_video_errors", 
                                                      "vid1_too_short", "vid2_too_short")])

```


```{r att_check_calculate_long, eval=TRUE, echo=FALSE}
data_final_long <- data_final[data_final$session_full == TRUE, ]

data_final_long$att_check_item_errors_t1_t4 <- calculate_att_check_item_errors_t1_t4(data=data_final_long, 
                                                                          var1 = "att_check1.t1", var2 = "att_check2.t1",
                                                                          var3 = "att_check1.t2", var4 = "att_check2.t2",
                                                                          var5 = "att_check1.t3", var6 = "att_check2.t3", 
                                                                          var7 = "att_check1.t4", var8 = "att_check2.t4", 
                                                                          var9 = "att_check3.t4")

data_final_long$att_check_sum_t1_t4 <- rowSums(data_final_long[, c("att_check_item_errors_t1_t4", "att_check_video_errors", 
                                                         "vid1_too_short", "vid2_too_short")])

# check errors by session
att_check_items_t1_t4 <- c("session", 
                           "att_check_sum_t1_t4", 
                           "att_check_item_errors_t1", "att_check_video_errors", "vid1_too_short", "vid2_too_short",    # @t1
                           "voucher_yes_no.scP")  # Would you like to receive the $10 voucher? where 1=yes, 2=no
data_att_check_t1_t4 <- data_final_long[, att_check_items_t1_t4]
data_att_check_t1_t4[data_att_check_t1_t4$session == "AYfR-Zd4pJo7vF3Ru6k6IIFBViGrRYwjiGRv62n5rPD2KRYztpRZdhDGMG8w-8af", ]

# clear all helper data, but the final
# rm(list=setdiff(ls(), "data_final"))
 
```

```{r att_check_plot, eval=T, echo=F}
# baseline data  
plot_error_baseline(data=data_final)

# longitudinal data  
plot_error_longitudinal(data=data_final_long)

```




```{r final_data_bl_exclude_cheaters, eval=T, echo=T}

## final data BASELINE
N_baseline_all <- length(data_final$session)
data_final_bl <- data_final[data_final$att_check_sum_t1 <= 1,]
N_baseline_noError <- length(data_final_bl$session)

N_errors_baseline <- list(
    "total number of baseline data rows" = N_baseline_all,
    "total number of participants with too many (>1) errors T1" = N_baseline_all - N_baseline_noError,
    "total number of clean (final) data" = N_baseline_noError)
N_errors_baseline

```


```{r final_data_long_exclude_cheaters, eval=T, echo=T}
## final data LONGITUDINAL
# exclude errors > 3 on longitudinal

# data_final_long <- data_final[data_final$session_full == TRUE, ]
N_fulldata_long <- length(data_final_long$session_full)


data_final_long <- data_final_long[data_final_long$att_check_sum_t1_t4 < 3,]
N_cleandata_long <- length(data_final_long$session_full)

exclude_errors_long <- list(
        "total number of baseline data rows" = N_fulldata_long,
        "total number of participants with too many (>2) errors T1-T4" = N_fulldata_long - N_cleandata_long,
        "total number of clean data" = N_cleandata_long)
exclude_errors_long

```

```{r save_final_data}
# remove IP address before publishing data
data_final_bl %>% select(-starts_with("ip_address"))
data_final_long %>% select(-starts_with("ip_address"))

# keep baseline data only
data_final_bl <-  data_final_bl[, c(grep(".+.t1$", names(data_final_bl), value=T), 
                                    grep("session", names(data_final_bl), value=T), 
                                    grep(".+.sc$", names(data_final_bl), value=T))]

## save final  data
if (overwrite_data) {
  write.csv2(data_final_bl, file="../../Data/data_final_bl.csv")
  write.csv2(data_final_long, file="../../Data/data_final_long.csv")
}

```





